{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "import scipy.io\n",
    "import h5py\n",
    "import torch.utils.data as Data\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = 'deepsea_train/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## VALIDATION DATA ###\n",
    "valid_data_raw = scipy.io.loadmat(DATA_PATH+'valid.mat')\n",
    "x_valid = torch.FloatTensor(valid_data_raw['validxdata'])\n",
    "y_valid = torch.FloatTensor(valid_data_raw['validdata'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each training sample consists of a 1,000-bp sequence from the human GRCh37 reference genome centered on each 200-bp bin and is paired with a label vector for 919 chromatin features. \n",
    "\n",
    "The 1,000-bp DNA sequence is represented by a 1,000 Ã— 4 binary matrix, with columns corresponding to A, G, C and T."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Sea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfeats = 4\n",
    "height = 1\n",
    "nkernels = [320,480,960]\n",
    "dropouts = [0.2,0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class deep_sea_nn(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=nfeats,      out_channels=nkernels[0], kernel_size=8)\n",
    "        self.conv2 = nn.Conv1d(in_channels=nkernels[0], out_channels=nkernels[1], kernel_size=8)\n",
    "        self.conv3 = nn.Conv1d(in_channels=nkernels[1], out_channels=nkernels[2], kernel_size=8)\n",
    "        self.maxpool = nn.MaxPool1d(kernel_size=4, stride=4)\n",
    "        self.drop1 = nn.Dropout(p=dropouts[0])\n",
    "        self.drop2 = nn.Dropout(p=dropouts[1])\n",
    "        self.linear1 = nn.Linear(53*960, 925)\n",
    "        self.linear2 = nn.Linear(925, 919)\n",
    "    \n",
    "    def foward(self, input):\n",
    "        ## convolution 1 ##\n",
    "        ds = self.conv1(input)\n",
    "        ds = F.relu(ds)\n",
    "        ds = self.maxpool(ds)\n",
    "        ds = self.drop1(ds)\n",
    "        \n",
    "        ## convolution 2 ##\n",
    "        ds = self.conv2(ds)\n",
    "        ds = F.relu(ds)\n",
    "        ds = self.maxpool(ds)\n",
    "        ds = self.drop1(ds)\n",
    "        \n",
    "        ## convolution 3 ##\n",
    "        ds = self.conv3(ds)\n",
    "        ds = F.relu(ds)\n",
    "        ds = self.drop2(ds)\n",
    "        \n",
    "        ds = ds.view(-1, 53*960)\n",
    "        ds = self.linear1(ds)\n",
    "        ds = F.relu(ds)\n",
    "        ds = self.linear2(ds)\n",
    "        \n",
    "        return ds\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## HYPERPARMETERS\n",
    "params = {'batch_size': 100,'num_workers': 2}\n",
    "device = 'cuda'\n",
    "\n",
    "learning_rate = 0.01\n",
    "batch_size = 100\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deep_sea_nn(\n",
      "  (conv1): Conv1d(4, 320, kernel_size=(8,), stride=(1,))\n",
      "  (conv2): Conv1d(320, 480, kernel_size=(8,), stride=(1,))\n",
      "  (conv3): Conv1d(480, 960, kernel_size=(8,), stride=(1,))\n",
      "  (maxpool): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "  (drop1): Dropout(p=0.2)\n",
      "  (drop2): Dropout(p=0.5)\n",
      "  (linear1): Linear(in_features=50880, out_features=925, bias=True)\n",
      "  (linear2): Linear(in_features=925, out_features=919, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "deep_sea = deep_sea_nn()\n",
    "deep_sea.to(device)\n",
    "print(deep_sea)\n",
    "\n",
    "optimizer = optim.SGD(deep_sea.parameters(), lr=learning_rate,momentum=0.9)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5,verbose=1)\n",
    "loss_func = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_loader = Data.DataLoader(dataset=Data.TensorDataset(x_valid, y_valid), shuffle=False,**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### Training Epoch 1/10.. Training data Part: 0.. \n",
      "#### Training part time elapsed: 197.79401326179504\n",
      "#### Training Epoch 1/10.. Training data Part: 1.. \n",
      "#### Training part time elapsed: 196.35107254981995\n",
      "#### Training Epoch 1/10.. Training data Part: 2.. \n",
      "#### Training part time elapsed: 190.28271985054016\n",
      "#### Training Epoch 1/10.. Training data Part: 3.. \n",
      "#### Training part time elapsed: 190.31472516059875\n",
      "#### Training Epoch 1/10.. Training data Part: 4.. \n",
      "#### Training part time elapsed: 190.23392343521118\n",
      "#### Training Epoch 1/10.. Training data Part: 5.. \n",
      "#### Training part time elapsed: 190.38456225395203\n",
      "#### Training Epoch 1/10.. Training data Part: 6.. \n",
      "#### Training part time elapsed: 190.350346326828\n",
      "#### Training Epoch 1/10.. Training data Part: 7.. \n",
      "#### Training part time elapsed: 190.38146138191223\n",
      "#### Training Epoch 1/10.. Training data Part: 8.. \n",
      "#### Training part time elapsed: 191.61573696136475\n",
      "#### Training Epoch 1/10.. Training data Part: 9.. \n",
      "#### Training part time elapsed: 193.99666166305542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/erick/anaconda3/envs/secure_private_ai/lib/python3.6/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type deep_sea_nn. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10.. Train loss: 0.09881587326526642.. Validation loss: 0.08267591148614883.. \n",
      "#### Training Epoch 2/10.. Training data Part: 0.. \n",
      "#### Training part time elapsed: 190.67163372039795\n",
      "#### Training Epoch 2/10.. Training data Part: 1.. \n",
      "#### Training part time elapsed: 194.55890226364136\n",
      "#### Training Epoch 2/10.. Training data Part: 2.. \n",
      "#### Training part time elapsed: 193.54051995277405\n",
      "#### Training Epoch 2/10.. Training data Part: 3.. \n",
      "#### Training part time elapsed: 192.52011895179749\n",
      "#### Training Epoch 2/10.. Training data Part: 4.. \n",
      "#### Training part time elapsed: 192.25975799560547\n",
      "#### Training Epoch 2/10.. Training data Part: 5.. \n",
      "#### Training part time elapsed: 192.20218181610107\n",
      "#### Training Epoch 2/10.. Training data Part: 6.. \n",
      "#### Training part time elapsed: 192.2119061946869\n",
      "#### Training Epoch 2/10.. Training data Part: 7.. \n",
      "#### Training part time elapsed: 192.29465055465698\n",
      "#### Training Epoch 2/10.. Training data Part: 8.. \n",
      "#### Training part time elapsed: 192.51175904273987\n",
      "#### Training Epoch 2/10.. Training data Part: 9.. \n",
      "#### Training part time elapsed: 192.23651361465454\n",
      "Epoch 2/10.. Train loss: 0.09172996878623962.. Validation loss: 0.07776300609111786.. \n",
      "#### Training Epoch 3/10.. Training data Part: 0.. \n",
      "#### Training part time elapsed: 192.22142219543457\n",
      "#### Training Epoch 3/10.. Training data Part: 1.. \n",
      "#### Training part time elapsed: 192.12876677513123\n",
      "#### Training Epoch 3/10.. Training data Part: 2.. \n",
      "#### Training part time elapsed: 192.46735310554504\n",
      "#### Training Epoch 3/10.. Training data Part: 3.. \n",
      "#### Training part time elapsed: 192.26014709472656\n",
      "#### Training Epoch 3/10.. Training data Part: 4.. \n",
      "#### Training part time elapsed: 192.3715798854828\n",
      "#### Training Epoch 3/10.. Training data Part: 5.. \n",
      "#### Training part time elapsed: 192.19221258163452\n",
      "#### Training Epoch 3/10.. Training data Part: 6.. \n",
      "#### Training part time elapsed: 192.10316252708435\n",
      "#### Training Epoch 3/10.. Training data Part: 7.. \n",
      "#### Training part time elapsed: 192.20942544937134\n",
      "#### Training Epoch 3/10.. Training data Part: 8.. \n",
      "#### Training part time elapsed: 192.1915318965912\n",
      "#### Training Epoch 3/10.. Training data Part: 9.. \n",
      "#### Training part time elapsed: 192.15466356277466\n",
      "Epoch 3/10.. Train loss: 0.07784777879714966.. Validation loss: 0.08223871886730194.. \n",
      "#### Training Epoch 4/10.. Training data Part: 0.. \n",
      "#### Training part time elapsed: 192.15466165542603\n",
      "#### Training Epoch 4/10.. Training data Part: 1.. \n",
      "#### Training part time elapsed: 192.2517695426941\n",
      "#### Training Epoch 4/10.. Training data Part: 2.. \n",
      "#### Training part time elapsed: 192.14616227149963\n",
      "#### Training Epoch 4/10.. Training data Part: 3.. \n",
      "#### Training part time elapsed: 192.14746594429016\n",
      "#### Training Epoch 4/10.. Training data Part: 4.. \n",
      "#### Training part time elapsed: 192.07438111305237\n",
      "#### Training Epoch 4/10.. Training data Part: 5.. \n",
      "#### Training part time elapsed: 192.1555004119873\n",
      "#### Training Epoch 4/10.. Training data Part: 6.. \n",
      "#### Training part time elapsed: 191.97067284584045\n",
      "#### Training Epoch 4/10.. Training data Part: 7.. \n",
      "#### Training part time elapsed: 192.15503931045532\n",
      "#### Training Epoch 4/10.. Training data Part: 8.. \n",
      "#### Training part time elapsed: 192.02776455879211\n",
      "#### Training Epoch 4/10.. Training data Part: 9.. \n",
      "#### Training part time elapsed: 192.15773606300354\n",
      "Epoch 4/10.. Train loss: 0.08226369321346283.. Validation loss: 0.07605240494012833.. \n",
      "#### Training Epoch 5/10.. Training data Part: 0.. \n",
      "#### Training part time elapsed: 191.9761188030243\n",
      "#### Training Epoch 5/10.. Training data Part: 1.. \n",
      "#### Training part time elapsed: 192.01857161521912\n",
      "#### Training Epoch 5/10.. Training data Part: 2.. \n",
      "#### Training part time elapsed: 192.0585799217224\n",
      "#### Training Epoch 5/10.. Training data Part: 3.. \n",
      "#### Training part time elapsed: 191.89867544174194\n",
      "#### Training Epoch 5/10.. Training data Part: 4.. \n",
      "#### Training part time elapsed: 191.942538022995\n",
      "#### Training Epoch 5/10.. Training data Part: 5.. \n",
      "#### Training part time elapsed: 192.10041451454163\n",
      "#### Training Epoch 5/10.. Training data Part: 6.. \n",
      "#### Training part time elapsed: 192.0036928653717\n",
      "#### Training Epoch 5/10.. Training data Part: 7.. \n",
      "#### Training part time elapsed: 192.09968447685242\n",
      "#### Training Epoch 5/10.. Training data Part: 8.. \n",
      "#### Training part time elapsed: 192.15493845939636\n",
      "#### Training Epoch 5/10.. Training data Part: 9.. \n",
      "#### Training part time elapsed: 192.14444136619568\n",
      "Epoch 5/10.. Train loss: 0.07899907976388931.. Validation loss: 0.07438723742961884.. \n",
      "#### Training Epoch 6/10.. Training data Part: 0.. \n",
      "#### Training part time elapsed: 191.9616551399231\n",
      "#### Training Epoch 6/10.. Training data Part: 1.. \n",
      "#### Training part time elapsed: 192.08887839317322\n",
      "#### Training Epoch 6/10.. Training data Part: 2.. \n",
      "#### Training part time elapsed: 192.05100631713867\n",
      "#### Training Epoch 6/10.. Training data Part: 3.. \n",
      "#### Training part time elapsed: 192.07227325439453\n",
      "#### Training Epoch 6/10.. Training data Part: 4.. \n",
      "#### Training part time elapsed: 192.07140445709229\n",
      "#### Training Epoch 6/10.. Training data Part: 5.. \n",
      "#### Training part time elapsed: 191.77483320236206\n",
      "#### Training Epoch 6/10.. Training data Part: 6.. \n",
      "#### Training part time elapsed: 191.85264611244202\n",
      "#### Training Epoch 6/10.. Training data Part: 7.. \n",
      "#### Training part time elapsed: 191.76798915863037\n",
      "#### Training Epoch 6/10.. Training data Part: 8.. \n",
      "#### Training part time elapsed: 191.8755578994751\n",
      "#### Training Epoch 6/10.. Training data Part: 9.. \n",
      "#### Training part time elapsed: 192.04096102714539\n",
      "Epoch 6/10.. Train loss: 0.08825893700122833.. Validation loss: 0.07735223323106766.. \n",
      "#### Training Epoch 7/10.. Training data Part: 0.. \n",
      "#### Training part time elapsed: 191.8072850704193\n",
      "#### Training Epoch 7/10.. Training data Part: 1.. \n",
      "#### Training part time elapsed: 191.91444373130798\n",
      "#### Training Epoch 7/10.. Training data Part: 2.. \n",
      "#### Training part time elapsed: 191.9058380126953\n",
      "#### Training Epoch 7/10.. Training data Part: 3.. \n",
      "#### Training part time elapsed: 191.87081146240234\n",
      "#### Training Epoch 7/10.. Training data Part: 4.. \n",
      "#### Training part time elapsed: 191.8152678012848\n",
      "#### Training Epoch 7/10.. Training data Part: 5.. \n",
      "#### Training part time elapsed: 191.82989120483398\n",
      "#### Training Epoch 7/10.. Training data Part: 6.. \n",
      "#### Training part time elapsed: 191.7288899421692\n",
      "#### Training Epoch 7/10.. Training data Part: 7.. \n",
      "#### Training part time elapsed: 191.64244079589844\n",
      "#### Training Epoch 7/10.. Training data Part: 8.. \n",
      "#### Training part time elapsed: 191.6372058391571\n",
      "#### Training Epoch 7/10.. Training data Part: 9.. \n",
      "#### Training part time elapsed: 191.8327760696411\n",
      "Epoch 7/10.. Train loss: 0.06671270728111267.. Validation loss: 0.07620855420827866.. \n",
      "#### Training Epoch 8/10.. Training data Part: 0.. \n",
      "#### Training part time elapsed: 191.86061072349548\n",
      "#### Training Epoch 8/10.. Training data Part: 1.. \n",
      "#### Training part time elapsed: 191.88991451263428\n",
      "#### Training Epoch 8/10.. Training data Part: 2.. \n",
      "#### Training part time elapsed: 191.85024189949036\n",
      "#### Training Epoch 8/10.. Training data Part: 3.. \n",
      "#### Training part time elapsed: 191.91357421875\n",
      "#### Training Epoch 8/10.. Training data Part: 4.. \n",
      "#### Training part time elapsed: 191.87000727653503\n",
      "#### Training Epoch 8/10.. Training data Part: 5.. \n",
      "#### Training part time elapsed: 191.74409246444702\n",
      "#### Training Epoch 8/10.. Training data Part: 6.. \n",
      "#### Training part time elapsed: 191.65058875083923\n",
      "#### Training Epoch 8/10.. Training data Part: 7.. \n",
      "#### Training part time elapsed: 191.71815180778503\n",
      "#### Training Epoch 8/10.. Training data Part: 8.. \n",
      "#### Training part time elapsed: 191.84518480300903\n",
      "#### Training Epoch 8/10.. Training data Part: 9.. \n",
      "#### Training part time elapsed: 191.77417850494385\n",
      "Epoch 8/10.. Train loss: 0.07520079612731934.. Validation loss: 0.07456742972135544.. \n",
      "#### Training Epoch 9/10.. Training data Part: 0.. \n",
      "#### Training part time elapsed: 191.63180804252625\n",
      "#### Training Epoch 9/10.. Training data Part: 1.. \n",
      "#### Training part time elapsed: 191.5762162208557\n",
      "#### Training Epoch 9/10.. Training data Part: 2.. \n",
      "#### Training part time elapsed: 191.7066309452057\n",
      "#### Training Epoch 9/10.. Training data Part: 3.. \n",
      "#### Training part time elapsed: 191.65180587768555\n",
      "#### Training Epoch 9/10.. Training data Part: 4.. \n",
      "#### Training part time elapsed: 191.5469467639923\n",
      "#### Training Epoch 9/10.. Training data Part: 5.. \n",
      "#### Training part time elapsed: 191.73459267616272\n",
      "#### Training Epoch 9/10.. Training data Part: 6.. \n",
      "#### Training part time elapsed: 191.5248076915741\n",
      "#### Training Epoch 9/10.. Training data Part: 7.. \n",
      "#### Training part time elapsed: 191.35201382637024\n",
      "#### Training Epoch 9/10.. Training data Part: 8.. \n",
      "#### Training part time elapsed: 191.594801902771\n",
      "#### Training Epoch 9/10.. Training data Part: 9.. \n",
      "#### Training part time elapsed: 191.46740794181824\n",
      "Epoch 9/10.. Train loss: 0.06984399259090424.. Validation loss: 0.07484239339828491.. \n",
      "#### Training Epoch 10/10.. Training data Part: 0.. \n",
      "#### Training part time elapsed: 191.48679852485657\n",
      "#### Training Epoch 10/10.. Training data Part: 1.. \n",
      "#### Training part time elapsed: 191.57743096351624\n",
      "#### Training Epoch 10/10.. Training data Part: 2.. \n",
      "#### Training part time elapsed: 191.42068719863892\n",
      "#### Training Epoch 10/10.. Training data Part: 3.. \n",
      "#### Training part time elapsed: 191.58145880699158\n",
      "#### Training Epoch 10/10.. Training data Part: 4.. \n",
      "#### Training part time elapsed: 191.51371264457703\n",
      "#### Training Epoch 10/10.. Training data Part: 5.. \n",
      "#### Training part time elapsed: 191.55516028404236\n",
      "#### Training Epoch 10/10.. Training data Part: 6.. \n",
      "#### Training part time elapsed: 191.56381106376648\n",
      "#### Training Epoch 10/10.. Training data Part: 7.. \n",
      "#### Training part time elapsed: 191.58256649971008\n",
      "#### Training Epoch 10/10.. Training data Part: 8.. \n",
      "#### Training part time elapsed: 191.4653844833374\n",
      "#### Training Epoch 10/10.. Training data Part: 9.. \n",
      "#### Training part time elapsed: 191.58881044387817\n",
      "Epoch 10/10.. Train loss: 0.05454450100660324.. Validation loss: 0.06732532382011414.. \n",
      "#### Training time : 21231.24547457695\n"
     ]
    }
   ],
   "source": [
    "train_losses, valid_losses = [], []\n",
    "running_loss = 0\n",
    "running_val_loss = 0\n",
    "\n",
    "start_time = time.time()\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0\n",
    "    deep_sea.train()\n",
    "    ### for each part of the training set ###\n",
    "    for i in range(0,10):\n",
    "        x_train_part = torch.FloatTensor(np.load(DATA_PATH+\"x_train_part_{}.npy\".format(i)))\n",
    "        y_train_part = torch.FloatTensor(np.load(DATA_PATH+\"y_train_part_{}.npy\".format(i)))\n",
    "        \n",
    "        train_loader = Data.DataLoader(dataset=Data.TensorDataset(x_train_part, y_train_part), shuffle=True, **params)\n",
    "        print(f\"#### Training Epoch {epoch+1}/{epochs}.. \"\n",
    "              f\"Training data Part: {i}.. \")\n",
    "        \n",
    "        part_start_time = time.time()\n",
    "        for j, (inputs, labels) in enumerate(train_loader):\n",
    "\n",
    "            \n",
    "            x, y = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            out = deep_sea.foward(x)\n",
    "            loss = loss_func(out.to(device), y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss = loss.item()\n",
    "            train_losses.append(running_loss)\n",
    "            \n",
    "        part_time_elapsed = time.time() - part_start_time\n",
    "        print('#### Training part time elapsed:', part_time_elapsed)\n",
    "        \n",
    "    if (epoch+1) % 5 == 0:\n",
    "        torch.save(deep_sea, 'deep_sea_model_training_epoch_{e}.pth'.format(e=epoch+1))\n",
    "        torch.save(deep_sea.state_dict(), 'deep_sea_model_training_epoch_{e}_params.pth'.format(e=epoch+1))\n",
    "            \n",
    "    ## Validation ##\n",
    "    running_val_loss = 0\n",
    "    for i, (inputs, labels) in enumerate(valid_loader):\n",
    "        deep_sea.eval()\n",
    "        with torch.no_grad():\n",
    "            x, y = inputs.to(device), labels.to(device)\n",
    "\n",
    "            val_out = deep_sea.foward(x)\n",
    "            val_loss = loss_func(val_out, y)\n",
    "\n",
    "            running_val_loss = val_loss.item()\n",
    "            valid_losses.append(running_val_loss)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs}.. \"\n",
    "          f\"Train loss: {running_loss}.. \"\n",
    "          f\"Validation loss: {running_val_loss}.. \")\n",
    "    \n",
    "            \n",
    "time_elapsed = time.time() - start_time\n",
    "print('#### Training time :', time_elapsed)\n",
    "\n",
    "torch.save(deep_sea, 'deep_sea_model.pth')\n",
    "torch.save(deep_sea.state_dict(), 'deep_sea_model_params.pth'.format(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.897568055555555"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "21231.245/3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(0,len(train_losses)), train_losses,'-b', label='Training')\n",
    "plt.plot(np.arange(0,len(valid_losses)), valid_losses,'-g', label='Validation')\n",
    "plt.legend(loc='lower right', frameon=False)\n",
    "plt.ylim(top = 0.5, bottom = 0.0)\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epochs');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
